from sklearn.feature_extraction.text import TfidfVectorizer

TEXT_COLUMNS = {{ columns }}
temp_train_data = {{ train_dataset }}[TEXT_COLUMNS]
# Make the entire dataframe sparse to avoid it converting into a dense matrix.
{{ train_dataset }} = {{ train_dataset }}.drop(TEXT_COLUMNS, axis=1).astype(pd.SparseDtype('float64', 0))
vectorizers = {}

{% if pipeline.config.use_word_list %}
{% if pipeline.config.use_word_list is mapping %}
# Use only specified words as features for each column
use_word_list = {{ pipeline.config.use_word_list }}
for col, word_list in use_word_list.items():
    word_list = [word.lower() for word in word_list]
    word_list = list(set(word_list))
    use_word_list[col] = word_list
for _col in TEXT_COLUMNS:
    tfidfvectorizer = TfidfVectorizer(max_features=3000, vocabulary=use_word_list.get(_col))
    vector_train = tfidfvectorizer.fit_transform(temp_train_data[_col])
    feature_names = ['_'.join([_col, name]) for name in tfidfvectorizer.get_feature_names_out()]
    vector_train = pd.DataFrame.sparse.from_spmatrix(vector_train, columns=feature_names, index=temp_train_data.index)
    {{ train_dataset }} = pd.concat([{{ train_dataset }}, vector_train], axis=1)
    vectorizers[_col] = tfidfvectorizer
{% else %}
# Use only specified words as features
use_word_list = {{ pipeline.config.use_word_list }}
use_word_list = [word.lower() for word in use_word_list]
use_word_list = list(set(use_word_list))
for _col in TEXT_COLUMNS:
    tfidfvectorizer = TfidfVectorizer(max_features=3000, vocabulary=use_word_list)
    vector_train = tfidfvectorizer.fit_transform(temp_train_data[_col])
    feature_names = ['_'.join([_col, name]) for name in tfidfvectorizer.get_feature_names_out()]
    vector_train = pd.DataFrame.sparse.from_spmatrix(vector_train, columns=feature_names, index=temp_train_data.index)
    {{ train_dataset }} = pd.concat([{{ train_dataset }}, vector_train], axis=1)
    vectorizers[_col] = tfidfvectorizer
{% endif %}
{% else %}
for _col in TEXT_COLUMNS:
    tfidfvectorizer = TfidfVectorizer(max_features=3000)
    vector_train = tfidfvectorizer.fit_transform(temp_train_data[_col])
    feature_names = ['_'.join([_col, name]) for name in tfidfvectorizer.get_feature_names_out()]
    vector_train = pd.DataFrame.sparse.from_spmatrix(vector_train, columns=feature_names, index=temp_train_data.index)
    {{ train_dataset }} = pd.concat([{{ train_dataset }}, vector_train], axis=1)
    vectorizers[_col] = tfidfvectorizer
{% endif %}

with open('tfidfVectorizer.pkl', 'wb') as f:
    pickle.dump(vectorizers, f)